import requests
from  bs4 import  BeautifulSoup as bs


# 使用def定义函数，myurl是函数的参数
def get_url_name(myurl):
    user_agent =  "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36"

    header = {'user-agent' : user_agent}
    response = requests.get(myurl, headers=header)
    bs_info = bs(response.text, 'html.parser')
    #bs_info = bs(response.text, 'html.parser')


# 使用for方法
    for tags in bs_info.find_all('div', attrs={'class': 'hd'}):
        for atag in tags.find_all('a',):
        
        #获取所有链接 
            print(atag.get('herf'))
        #获取电影名字
            print(atag.find('span',).text)

#生成包含所有页面的元组

urls = tuple(f'https://movie.douban.com/top250?start={ page * 25}&filter=' for page in range(10))
print (urls)

# 设置控制请求的频率， 引入了time的模块
from time import  sleep
sleep(10)

for page in urls:
    get_url_name(page)
    sleep(5)


